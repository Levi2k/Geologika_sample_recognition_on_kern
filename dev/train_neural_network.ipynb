{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "661f4995",
   "metadata": {},
   "source": [
    "### Neural network for detecting text on kern (yolov5 and Roboflow)\n",
    "  Neural network was learned on database, which includes photos with different filters. The main idea is to crop the bboxes with text and then to read the text using pytesseract. The goal is to make the task easier for Pytesseract by decreasing the area for text recognition. You can use this notebook to train neural network on your own database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f3679b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd yolov5 ##-----Start working in yolov5 directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d3f89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ----Installing yolov5\n",
    "!git clone https://github.com/ultralytics/yolov5 \n",
    "%cd yolov5\n",
    "!git reset --hard 886f1c03d839575afecb059accf74296fad395b6 \n",
    "!pip install -qr requirements.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeb47e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## -----Imports\n",
    "import torch\n",
    "from utils.google_utils import gdrive_download\n",
    "\n",
    "from IPython.core.magic import register_line_cell_magic\n",
    "\n",
    "import glob\n",
    "from IPython.display import Image, clear_output, display\n",
    "from utils.plots import plot_results\n",
    "\n",
    "from roboflow import Roboflow\n",
    "import yaml\n",
    "\n",
    "## -----Settings torch\n",
    "clear_output()\n",
    "print('Setup complete. Using torch %s %s' %(torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))\n",
    "rf = Roboflow(model_format=\"yolov5\", notebook=\"Text recognition\")\n",
    "\n",
    "## -----Getting database\n",
    "!curl -L \"https://app.roboflow.com/ds/t14ibAqfCx?key=QQfQW48td3\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip\n",
    "\n",
    "## ----Define number of classes based on YAML\n",
    "with open(\"data.yaml\", 'r') as stream:\n",
    "    num_classes = str(yaml.safe_load(stream)['nc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5925650b",
   "metadata": {},
   "source": [
    "### Customizing writefile and configuring neural network parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6244a076",
   "metadata": {},
   "outputs": [],
   "source": [
    "## -----Customize iPython writefile so we can write variables\n",
    "\n",
    "@register_line_cell_magic\n",
    "def writetemplate(line, cell):\n",
    "    with open(line, 'w') as f:\n",
    "        f.write(cell.format(**globals()))\n",
    "%%writetemplate custom_yolov5m.yaml\n",
    "\n",
    "## -----Neural network structure\n",
    "nc: {num_classes}  # number of classes\n",
    "depth_multiple: 0.33  # model depth multiple\n",
    "width_multiple: 0.50  # layer channel multiple\n",
    "\n",
    "anchors:\n",
    "  - [10,13, 16,30, 33,23]  # P3/8\n",
    "  - [30,61, 62,45, 59,119]  # P4/16\n",
    "  - [116,90, 156,198, 373,326]  # P5/32\n",
    "\n",
    "backbone:\n",
    "## -----[from, number, module, args]\n",
    "  [[-1, 1, Focus, [64, 3]],  # 0-P1/2 \n",
    "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
    "   [-1, 3, BottleneckCSP, [128]],\n",
    "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
    "   [-1, 9, BottleneckCSP, [256]],\n",
    "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
    "   [-1, 9, BottleneckCSP, [512]],\n",
    "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
    "   [-1, 1, SPP, [1024, [5, 9, 13]]],\n",
    "   [-1, 3, BottleneckCSP, [1024, False]],  # 9\n",
    "  ]\n",
    "\n",
    "## -----YOLOv5 head\n",
    "head:\n",
    "  [[-1, 1, Conv, [512, 1, 1]],\n",
    "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
    "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
    "   [-1, 3, BottleneckCSP, [512, False]],  # 13\n",
    "\n",
    "   [-1, 1, Conv, [256, 1, 1]],\n",
    "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
    "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
    "   [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3/8-small)\n",
    "\n",
    "   [-1, 1, Conv, [256, 3, 2]],\n",
    "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
    "   [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4/16-medium)\n",
    "\n",
    "   [-1, 1, Conv, [512, 3, 2]],\n",
    "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
    "   [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5/32-large)\n",
    "\n",
    "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
    "  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807834a2",
   "metadata": {},
   "source": [
    "### Choosing the number of batches and epochs, starting training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181fdb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --img 416 --batch 32 --epochs 10000 --data 'data.yaml' --cfg ./custom_yolov5m.yaml --weights '' --name yolov5s_results  --cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a09cb8b",
   "metadata": {},
   "source": [
    "### Plotting statistic results about lerning process and showing the result by examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60596d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='runs/train/yolov5s_results6/results.png', width=1000) ## plotting results\n",
    "print(\"GROUND TRUTH TRAINING DATA:\")  ## display our ground truth data\n",
    "Image(filename='runs/train/yolov5s_results6/test_batch0_labels.jpg', width=900)\n",
    "print(\"GROUND TRUTH TRAINING DATA:\") ## next, display our predicted label data\n",
    "Image(filename='runs/train/yolov5s_results6/test_batch0_pred.jpg', width=900)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bf70a4",
   "metadata": {},
   "source": [
    "### Cropping the image and getting bboxes with text on example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567438fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "% cd yolov5\n",
    "!python detect.py --weights runs/train/yolov5s_results6/weights/best.pt --img 37 --conf 0.4 --source ./test/images\n",
    "\n",
    "!python detect3.py --weights runs/train/yolov5s_results6/weights/best.pt --img 37 --conf 0.4 --source test/images/33.jpg\n",
    "for imageName in glob.glob('runs/detect/exp2426/*.jpg'): #assuming JPG\n",
    "    display(Image(filename=imageName))\n",
    "    print(\"\\n\")\n",
    "    name='runs/detect/exp2426/*.jpg'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
